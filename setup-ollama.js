// OLLAMA SETUP SCRIPT FOR CRONUS
// Paste this into DevTools console to configure Ollama

async function setupOllama() {
  console.log('ü§ñ Setting up Ollama for Cronus...\n')

  try {
    // 1. Get available models
    const models = await window.electron.ipcRenderer.invoke('local:list-ollama-models')
    console.log('üì¶ Available Ollama models:')
    models.forEach(model => console.log(`   - ${model}`))

    // 2. Check if we have llama3.2 or llama3.2:latest
    const llama32 = models.find(m => m.startsWith('llama3.2'))

    if (!llama32) {
      console.log('\n‚ùå No llama3.2 model found!')
      console.log('üí° Please pull the model first:')
      console.log('   ollama pull llama3.2')
      return
    }

    console.log(`\n‚úÖ Found model: ${llama32}`)

    // 3. Update settings to use the correct model name
    console.log(`\n‚öôÔ∏è  Configuring Cronus to use: ${llama32}`)

    await window.electron.ipcRenderer.invoke('local:set-setting', 'ai_enabled', 'true')
    await window.electron.ipcRenderer.invoke('local:set-setting', 'categorization_enabled', 'true')
    await window.electron.ipcRenderer.invoke('local:set-setting', 'ollama_model', llama32)

    console.log('‚úÖ Settings updated:')
    console.log('   - AI Enabled: ‚úÖ')
    console.log('   - Categorization Enabled: ‚úÖ')
    console.log(`   - Ollama Model: ${llama32}`)

    // 4. Verify settings
    const settings = await window.electron.ipcRenderer.invoke('local:get-all-settings')
    console.log('\nüìã Current Settings:')
    console.log(`   - ai_enabled: ${settings.ai_enabled}`)
    console.log(`   - categorization_enabled: ${settings.categorization_enabled}`)
    console.log(`   - ollama_model: ${settings.ollama_model}`)

    console.log('\n‚úÖ Ollama is now configured!')
    console.log('üí° New events will be automatically categorized using AI.')
    console.log('üí° Watch the terminal for categorization logs.')

  } catch (error) {
    console.error('‚ùå Setup failed:', error)
    console.log('\nTroubleshooting:')
    console.log('1. Make sure Ollama is running: ollama serve')
    console.log('2. Check that llama3.2 is installed: ollama list')
    console.log('3. If not installed: ollama pull llama3.2')
  }
}

setupOllama()
